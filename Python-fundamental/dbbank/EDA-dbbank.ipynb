{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploretory data analysis on risk factors involved in investment by Deutch Bank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Deutsche Bank is a multinational investment bank and financial services company. It offers a range of investment products to its clients, including stocks, bonds, and derivatives. The bank is concerned about the risk of investment in various products and wants to use data analysis to identify and manage potential risks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "To perform data analysis on the investment products offered by Deutsche Bank and identify potential risks associated with each product.\n",
    "\n",
    "Technical chart for the reliance industries: \n",
    "\n",
    "1. MACD\n",
    "2. Momentum (MOM)\n",
    "3. Stochastic (STO)\n",
    "4. CCI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deutsch Bank share\n",
    "With this dataset, we could perform a wide range of analyses and visualizations to understand how the stock price of Deutsche Bank has changed over time, and to identify trends or patterns in the data. \n",
    "\n",
    "For example, we could:\n",
    "\n",
    "- Create a line chart showing the daily closing price of the stock over time.\n",
    "- Calculate the daily percentage change in the stock price, and create a histogram or density plot to visualize the distribution of these changes.\n",
    "- Use technical analysis tools to identify patterns or trends in the stock price, such as moving averages or support/resistance levels.\n",
    "- Perform a regression analysis to model the relationship between the stock price and other variables, such as market indices or macroeconomic indicators.\n",
    "- Use machine learning algorithms to predict future stock prices based on historical data.\n",
    "\n",
    "So, I will start with few basic things with these datas over time and compare them with each other.\n",
    "\n",
    "1. **Basic data exploration:** You can use pandas to perform basic exploration of the data, such as checking the dimensions of the DataFrame, looking at summary statistics, or checking for missing values\n",
    "    - summary statistics: `.describe()`\n",
    "    - dimensions of the DataFrame: `.shape()`\n",
    "    - check for missing values: `.isnull().sum())`\n",
    "2. Visualize the data using matplotlib and seaborn\n",
    "\n",
    "3. Calculate returns\n",
    "\n",
    "4. Analyze relationships between variables\n",
    "\n",
    "5. Rolling statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About data\n",
    "\n",
    "To begin the analysis, the bank collects data on its investment products over the past 10 years. The data includes information on the product type, issuer, maturity date, credit rating, and other relevant factors that could impact risk.\n",
    "\n",
    "**Table summary:**\n",
    "\n",
    "| Sr. No. | Date | Open | High | Low | Close | Adj Close | Volume |\n",
    "|---------|------|------|------|-----|-------|-----------|--------|\n",
    "| ||||||||\n",
    "\n",
    "Here individual columns are\n",
    "\n",
    "| Column name | Description |\n",
    "|-------------|-------------|\n",
    "| Date | The date of the stock price, in a standardized format (e.g. YYYY-MM-DD). |\n",
    "| Open | The opening price of the stock on that day. | \n",
    "| High |  The highest price of the stock on that day. |\n",
    "| Low | The lowest price of the stock on that day. |\n",
    "| Close | The closing price of the stock on that day. |\n",
    "| Adj Close | The adjusted closing price of the stock on that day. This takes into account any corporate actions (such as stock splits or dividends) that may have affected the stock price. |\n",
    "| Volume | The volume of shares traded on that day. |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Download & preparation for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install yfinance --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this\n",
    "dataset_url = 'https://investor-relations.db.com/share/share-information/historical-share-prices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this\n",
    "data_dir = './dbbank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now listing the downloaded files \n",
    "import os\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"Deutch-bank-share\" # change this (use lowercase letters and hyphens only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project=\"Deutch-bank-share.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading xlr datafile\n",
    "%pip install xlrd --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pandas-datareader --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import pandas_datareader as pdr\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imorting files\n",
    "dbbank_df = pd.read_csv('./dbbank/deutschebank_share_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are seeing that rows 0-4 are not required. So we need to drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the first 5 rows\n",
    "dbbank_df = dbbank_df.iloc[5:]\n",
    "\n",
    "# set the 6th row as the column names\n",
    "dbbank_df.columns = dbbank_df.iloc[0]\n",
    "\n",
    "# delete the row with the old column names\n",
    "dbbank_df = dbbank_df.iloc[1:]\n",
    "\n",
    "# reset the index\n",
    "dbbank_df = dbbank_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the index column name\n",
    "dbbank_df = dbbank_df.rename_axis(None, axis=1)\n",
    "dbbank_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now downloading the data for other shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for the stock AAPL\n",
    "aapl_df = yf.download('AAPL','2006-01-01','2023-02-17')\n",
    "aapl_df = aapl_df.reset_index()\n",
    "aapl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank of Amerika\n",
    "bac_df = yf.download('BAC','2006-01-01','2023-02-17')\n",
    "bac_df = bac_df.reset_index()\n",
    "bac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank of Amerika\n",
    "bac_df = yf.download('BAC','2006-01-01','2023-02-17')\n",
    "bac_df = bac_df.reset_index()\n",
    "bac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citigroup\n",
    "citi_df = yf.download('C','2006-01-01','2023-02-17')\n",
    "citi_df = citi_df.reset_index()\n",
    "citi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goldman Sachs\n",
    "gs_df = yf.download('GS','2006-01-01','2023-02-17')\n",
    "gs_df = gs_df.reset_index()\n",
    "gs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPMorgan Chase\n",
    "jpm_df = yf.download('JPM','2006-01-01','2023-02-17')\n",
    "jpm_df = jpm_df.reset_index()\n",
    "jpm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morgan Stanlay\n",
    "ms_df = yf.download('MS','2006-01-01','2023-02-17')\n",
    "ms_df = ms_df.reset_index()\n",
    "ms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wells Fargo\n",
    "wf_df = yf.download('WF','2006-01-01','2023-02-17')\n",
    "wf_df = wf_df.reset_index()\n",
    "wf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc1_df = pd.concat([wf_df, ms_df])\n",
    "conc1_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a library of all immported share prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with the dataframes\n",
    "dfs = {'df1': dbbank_df, \n",
    "       'df2': aapl_df,\n",
    "       'df3': bac_df,\n",
    "       'df4': citi_df,\n",
    "       'df5': gs_df,\n",
    "       'df6': jpm_df,\n",
    "       'df7': ms_df}\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "To analyze the investment products, the bank uses Python libraries such as `numpy`, `scipy`, and `pandas` to perform statistical analysis on the data.\n",
    "\n",
    "1. First, the bank performs a descriptive analysis of the data to understand the distribution of investment products across various categories. This includes analyzing the frequency of each product type, issuer, and credit rating.\n",
    "\n",
    "2. Next, the bank uses machine learning techniques such as clustering and classification to identify patterns and potential risks in the data. For example, the bank may use a clustering algorithm to group similar investment products together based on their characteristics, such as credit rating and maturity date. The bank can then analyze the risk profile of each cluster and take appropriate measures to manage the risks.\n",
    "\n",
    "3. The bank may also use classification algorithms to predict the likelihood of default or other risks associated with a particular investment product. This can help the bank make informed decisions about which products to invest in and which to avoid.\n",
    "\n",
    "4. Finally, the bank visualizes the data using Python libraries such as `matplotlib` and `seaborn` to communicate the findings to stakeholders. This includes creating charts and graphs that show the distribution of investment products across various categories, as well as the risk profile of each product.\n",
    "\n",
    "In our present analysis, we will mostly focus on some of the basic type of data anlysis discuss in the 'Data Collection and preparation' section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Basic data exploration\n",
    "We can use pandas to perform basic exploration of the data, such as checking the dimensions of the DataFrame, looking at summary statistics, or checking for missing values\n",
    "    - summary statistics: `.describe()`\n",
    "    - dimensions of the DataFrame: `.shape()`\n",
    "    - check for missing values: `.isnull().sum())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing values i.e. NaN valuess\n",
    "dbbank_df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so good thing is we don't have any missing values in the dataframe of dbabnk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "dbbank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "dbbank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatype\n",
    "dbbank_df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we find that datee is object type and all other columns are of object type so we need to convert them to appropriate data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime format\n",
    "dbbank_df['Date'] = pd.to_datetime(dbbank_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the \"Date\" column as the index of the DataFrame\n",
    "dbbank_df.set_index(dbbank_df['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df['Open'] = dbbank_df['Open'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df['Close'] = dbbank_df['Close'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df['High'] = dbbank_df['High'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df['Low'] = dbbank_df['Low'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace commas with empty strings\n",
    "dbbank_df['Volume (shares)'] = dbbank_df['Volume (shares)'].str.replace(',', '')\n",
    "\n",
    "# Convert to float\n",
    "dbbank_df['Volume (shares)'] = dbbank_df['Volume (shares)'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.duplicated()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualize the data using matplotlib and seaborn:\n",
    "\n",
    "we can use these libraries to create a variety of charts and plots, such as line plots, bar plots, histograms, and scatter plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the closing price over time\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Close'])\n",
    "plt.title('Deutsche Bank Closing Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Calculate returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate daily returns\n",
    "dbbank_df['Return'] = dbbank_df['Close'].pct_change()\n",
    "# plot the returns over time\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Return'], 'go:')\n",
    "plt.title('Deutsche Bank Daily Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Return')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the `dbbank_df['Return']` column, `pct_change()` is applied to the `Close` column of the DataFrame, which contains the closing prices of Deutsche Bank's stock. The resulting `Return` column contains the daily percentage changes in the stock price."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Analyze relationships between variables\n",
    "You can use seaborn to create scatter plots and regression plots to explore the relationships between variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "# create a scatter plot of Open vs. Close\n",
    "sns.scatterplot(data=dbbank_df, x='Open', y='Close', color=\"blue\")\n",
    "plt.title('Deutsche Bank Open vs. Close')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot of Open vs. Close\n",
    "sns.scatterplot(data=dbbank_df, x='High', y='Low')\n",
    "plt.title('Deutsche Bank High vs. Low')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot of Open vs. Close\n",
    "sns.scatterplot(data=dbbank_df, x='High', y='Volume (shares)', color=\"g\")\n",
    "plt.title('Deutsche Bank Open vs. Close')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot with Regression Line using Seaborn\n",
    "sns.regplot(data=dbbank_df, y='Return', x='Volume (shares)', color = 'g')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Regression line: A regression line is an estimate of the line that describes the true, but unknown, linear relationship between the two variables.\n",
    "\n",
    "Clearly the two variables doesnot show a strong relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot with Regression Line using Seaborn\n",
    "sns.regplot(data=dbbank_df, y='High', x='Volume (shares)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can say that, wheen volume is high, the share prices go high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot with Marginal Histograms along with linear regression\n",
    "sns.jointplot(data=dbbank_df, x='High', y='Volume (shares)', kind=\"reg\", color='red', marker=\".\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "\n",
    "*Marginal distribution:* The marginal distribution of a variable is the probability distribution of that variable alone, ignoring the values of any other variables. For two variables, the marginal distribution of one variable can be obtained by summing the joint probability distribution over all values of the other variable.\n",
    "\n",
    "> For example, if X and Y are two random variables with joint probability distribution p(X, Y), the marginal distribution of X is given by p(X) = âˆ‘p(X, Y), where the sum is taken over all possible values of Y. Similarly, the marginal distribution of Y can be obtained by summing the joint distribution over all values of X.\n",
    "\n",
    "> It represents the bi-variate distribution using scatterplot() and the marginal distributions using histplot()."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Rolling statistics\n",
    "You can use pandas to calculate rolling statistics such as rolling mean, rolling standard deviation, and rolling correlation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to calculate the 30-day rolling mean of the closing price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling mean with window size 30\n",
    "rolling_mean = dbbank_df['Close'].rolling(window=30).mean()\n",
    "\n",
    "# Calculate rolling standard deviation with window size 30\n",
    "rolling_std = dbbank_df['Close'].rolling(window=30).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rolling mean over time\n",
    "plt.plot(dbbank_df['Date'], rolling_mean)\n",
    "plt.plot(dbbank_df['Date'], rolling_std)\n",
    "plt.title('Deutsche Bank 30-Day Rolling Mean of Closing Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Correlation:**\n",
    "\n",
    "    To calculate correlations, we need to calculate the shifted value.\n",
    "\n",
    "    > Shifting the rows in this case can be useful for calculating changes in the 'High' column values between consecutive time periods. By shifting the 'High' column one row downwards, you can compare each value with its previous value and calculate the change.\n",
    "\n",
    "    > For example, if you subtract the shifted 'High' column from the original 'High' column, you get a new column that contains the difference in 'High' values between each consecutive time period. This can be useful for calculating metrics like daily price changes or volatility.\n",
    "\n",
    "    > `dbbank_df['high_change'] = dbbank_df['High'] - dbbank_df['High'].shift()`\n",
    "\n",
    "    > In this code, the shift() method is used to shift the 'High' column one row downwards, so that each value in the 'High' column is now compared with its previous value. Note that the first value in the 'high_change' column will be `NaN`, as there is no previous value to subtract from the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another column with shifted values of 'value' column\n",
    "dbbank_df['shifted_high'] = dbbank_df['High'].shift()\n",
    "dbbank_df['shifted_low'] = dbbank_df['Low'].shift()\n",
    "dbbank_df['shifted_close'] = dbbank_df['Close'].shift()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we notice here that Date is used here as index as well as Column. This is due to the fact that we need some times Date as column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling correlation with window size 10\n",
    "rollinghigh_corr = dbbank_df['High'].rolling(window=10).corr(dbbank_df['shifted_high'])\n",
    "rollinglow_corr = dbbank_df['Low'].rolling(window=10).corr(dbbank_df['shifted_low'])\n",
    "rollingClose_corr = dbbank_df['Close'].rolling(window=10).corr(dbbank_df['shifted_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dbbank_df['High'], label='High')\n",
    "plt.plot(rolling_mean, label='Rolling Mean')\n",
    "plt.plot(rolling_std, label='Rolling Std')\n",
    "plt.plot(rollinghigh_corr, label='Correlation High')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly, high value does not correlations show any correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rollinghigh_corr, label='Correlation high with year')\n",
    "plt.plot(rollinglow_corr, label='Correlation low with year')\n",
    "plt.plot(rollingClose_corr, label='Correlation close with year')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dbbank_df['Close'], label='Close')\n",
    "plt.plot(rollingClose_corr, label='Correlation, close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Moving average convergence divergence (MACD)\n",
    "You can use pandas to calculate the MACD, a popular technical indicator used in trading. For example, to calculate the 12-day and 26-day exponential moving averages and the MACD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 12-day and 26-day exponential moving averages\n",
    "ema12 = dbbank_df['Close'].ewm(span=12, adjust=False).mean()\n",
    "ema26 = dbbank_df['Close'].ewm(span=26, adjust=False).mean()\n",
    "# calculate MACD\n",
    "macd = ema12 - ema26\n",
    "# plot the MACD over time\n",
    "plt.plot(dbbank_df['Date'], macd, label = 'MACD')\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Close'], label= \"Close\")\n",
    "plt.title('Deutsche Bank 2000-2023')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Bollinger Bands\n",
    "You can use pandas to calculate Bollinger Bands, another popular technical indicator used in trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 20-day moving average and standard deviation\n",
    "dbbank_df['MA20'] = dbbank_df['Close'].rolling(window=20).mean()\n",
    "dbbank_df['StdDev'] = dbbank_df['Close'].rolling(window=20).std()\n",
    "# calculate upper and lower Bollinger Bands\n",
    "dbbank_df['UpperBand'] = dbbank_df['MA20'] + 2 * dbbank_df['StdDev']\n",
    "dbbank_df['LowerBand'] = dbbank_df['MA20'] - 2 * dbbank_df['StdDev']\n",
    "# plot the Bollinger Bands over time\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Close'])\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['MA20'])\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['UpperBand'])\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['LowerBand'])\n",
    "plt.title('Deutsche Bank Bollinger Bands')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Compare with market indices\n",
    "You can use pandas to download and compare the Deutsche Bank share data with market indices such as the DAX, FTSE, or S&P 500. For example, to download the DAX data and compare it with the Deutsche Bank share data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. aapl_df = apple\n",
    "2. bac_df = Bank of amerika\n",
    "3. citi_df = citibank\n",
    "4. gs_df = Goldman Sachs\n",
    "5. jpm_df = JPMorgan\n",
    "6. ms_df = morgan Stanlay\n",
    "\n",
    "Columns:\n",
    "Date\t| Open\t| High\t| Low\t| Close\t| Adj Close\t| Volume |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_dfcopy = aapl_df.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bac_dfcopy = bac_df.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citi_dfcopy = citi_df.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dfcopy = gs_df.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_dfcopy = jpm_df.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_dfcopy =ms_df.drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_dfnew = dbbank_df.drop(['shifted_high', 'shifted_low', 'shifted_close', 'MA20', 'StdDev', 'UpperBand', 'LowerBand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1_df = pd.concat([dbbank_dfnew, aapl_dfcopy, bac_dfcopy, citi_dfcopy, gs_dfcopy, jpm_dfcopy, ms_dfcopy], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 2006-01-03\n",
    "end_date = 2023-02-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2_df = dbbank_df.merge(aapl_dfcopy, on='Date', how='left')\n",
    "merged2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Returns_DAX'] = dbbank_df['Close_dax'].pct_change()\n",
    "# plot the daily returns for Deutsche Bank and DAX over time\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Returns'], label='Deutsche Bank')\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Returns_DAX'], label='DAX')\n",
    "plt.title('Deutsche Bank vs. DAX Daily Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " # merge DAX data with Deutsche Bank share data\n",
    "df = pd.merge(dbbank_df, aapl_dfcopy, bac_dfcopy, citi_dfcopy, gs_dfcopy, jpm_dfcopy, ms_dfcopy , on='Date', suffixes=('_db', '_dax'))\n",
    "# calculate daily returns for DAX\n",
    "df['Returns_DAX'] = dbbank_df['Close_dax'].pct_change()\n",
    "# plot the daily returns for Deutsche Bank and DAX over time\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Returns'], label='Deutsche Bank')\n",
    "plt.plot(dbbank_df['Date'], dbbank_df['Returns_DAX'], label='DAX')\n",
    "plt.title('Deutsche Bank vs. DAX Daily Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Perform statistical analysis\n",
    "You can use pandas to perform statistical analysis on the Deutsche Bank share data. For example, to calculate the mean, standard deviation, and correlation coefficient of the closing price and volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean, standard deviation, and correlation coefficient of closing price and volume\n",
    "mean_close = dbbank_df['Close'].mean()\n",
    "std_close = dbbank_df['Close'].std()\n",
    "mean_volume = dbbank_df['Volume (shares)'].mean()\n",
    "std_volume = dbbank_df['Volume (shares)'].std()\n",
    "corr = dbbank_df['Close'].corr(dbbank_df['Volume (shares)'])\n",
    "print('Mean closing price:', mean_close)\n",
    "print('Standard deviation of closing price:', std_close)\n",
    "print('Mean volume:', mean_volume)\n",
    "print('Standard deviation of volume:', std_volume)\n",
    "print('Correlation coefficient of closing price and volume:', corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through data analysis, Deutsche Bank is able to identify potential risks associated with its investment products and take appropriate measures to manage those risks. This helps the bank make informed decisions about which products to invest in and which to avoid, ultimately reducing the overall risk of its investment portfolio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Set the ticker symbol for Deutsche Bank\n",
    "tickerdb = 'DB'\n",
    "tickerbac = 'BAC'\n",
    "\n",
    "# Download the live share price data for Deutsche Bank\n",
    "db_stock_data = yf.download([tickerdb,tickerbac], period='1d', interval='1m')\n",
    "\n",
    "# Download the live share price data for Deutsche Bank\n",
    "# bac_stock_data = yf.download(tickerbac, period='1d', interval='1m')\n",
    "\n",
    "# Create a pandas dataframe from the stock data\n",
    "db_df = pd.DataFrame(db_stock_data)\n",
    "\n",
    "# Print the dataframe to verify the data has been imported\n",
    "db_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra;**\n",
    "\n",
    "The below code shows how to get data for AAPL from 2016 to 2019 and plot the adjusted closing price of the data.\n",
    "\n",
    "https://towardsdatascience.com/historical-stock-price-data-in-python-a0b6dc826836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for the stock AAPL\n",
    "data = yf.download('AAPL','2016-01-01','2019-08-01')\n",
    "\n",
    "# Import the plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the close price of the AAPL\n",
    "data['Adj Close'].plot()\n",
    "plt.show()# Get the data for the stock AAPL\n",
    "data = yf.download('AAPL','2016-01-01','2019-08-01')\n",
    "\n",
    "# Import the plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the close price of the AAPL\n",
    "data['Adj Close'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for multiple stocks:\n",
    "\n",
    "In the below code, we will fetch the data of multiple stocks and store it in a dataframe data. Then we will calculate the daily returns and plot the cumulative returns of all the stock prices using matplotlib package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list = ['AAPL', 'WMT', 'IBM', 'MU', 'BA', 'AXP']\n",
    "\n",
    "# Fetch the data\n",
    "import yfinance as yf\n",
    "data = yf.download(tickers_list,'2015-1-1')['Adj Close']\n",
    "\n",
    "# Print first 5 rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the close prices\n",
    "((data.pct_change()+1).cumprod()).plot(figsize=(10, 7))\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Define the label for the title of the figure\n",
    "plt.title(\"Returns\", fontsize=16)\n",
    "\n",
    "# Define the labels for x-axis and y-axis\n",
    "plt.ylabel('Cumulative Returns', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "\n",
    "# Plot the grid lines\n",
    "plt.grid(which=\"major\", color='k', linestyle='-.', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minute level data:\n",
    "\n",
    "Through yfinance, you can also fetch the data of minute frequency. You can download for other frequency by just tweaking the interval parameter on line no 8 below. Following values are supported in the interval: 1m, 5m, 15m, 30m, 60m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import yfinance as yf\n",
    "\n",
    "# Get the data\n",
    "data = yf.download(tickers=\"MSFT\", period=\"5d\", interval=\"1m\")\n",
    "\n",
    "# Print the data\n",
    "print(data.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can analyze this data, create a trading strategy and analyze the performance of the strategy using the pyfolio package. It computes the Sharpe ratio, Sortino ratio, maximum drawdowns and many other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "1. https://investor-relations.db.com/share/share-information/historical-share-prices\n",
    "2. https://www.zaner.com/3.0/education/technicalstudies/MA.asp#top\n",
    "3. https://www.linkedin.com/pulse/stock-data-analysis-using-python-sakshi-grover/ (have to do some of these)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
